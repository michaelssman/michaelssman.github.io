# 视频编解码

直播捕捉到的视频信息，需要压缩（AAC/H264）

硬编码（AVFoundation已经实现）

## 数据冗余

**任何视频/音频的压缩都是针对冗余数据的压缩。**

视频压缩是针对数据冗余做的，只要接收端不会产生误解，就可以减少承载信息的数据量。

## 视频

- 内容元素
  - 图像信息（Image）
  - 音频（Audio）
  - 元信息（Metadata）
- 编码格式
  - Video：H264
  - Audio：AAC
- 容器封装
  - MP4、MOV、FLV、RM、RMVB、AVI

## 视频4个动作

1. 采集--视频源数据CVPixelBufferRef
2. 编码（硬编码VideoToolBox）--- NALU数据--- CMBlockBufferRef
3. 解码（硬解码VideoToolBox）--  NALU数据--- CVPixelBufferRef
4. 将数据显示到屏幕上（渲染）-- OpenGL ES视频渲染动作

## H264编码原理

### 1、帧内预测压缩，解决的是空域数据冗余问题

什么是空域数据：就是这幅图里数据在宽高空间内包含了很多颜色、光亮，**人的肉眼很难察觉的数据**，对于这些数据，我们可以认作冗余，直接压缩掉。有损压缩。

宏块预测模式信息得到预测图，通过预测图与原图的差得到一个结果（残差值），加上残差值就得到原图。

### 2、帧间预测压缩，解决的是时域冗余问题

摄像头在一段时间内所捕捉的数据没有较大变化，针对这**一时间内的相同数据压缩掉**，就叫时域数据压缩。

### 3、整数离散余弦变换（DCT），将空间上相关性变为频域上无关的数据然后进行量化

如果对傅里叶变换理解比较好的，对这个理解的比较快。傅里叶变换可以把一个复杂波形图变换成许多的正弦波，只是它们之间的频率不一样，振幅也不一样。如果它们在频率上没有一致性那么我们就可以对它进行压缩处理。

### 4、CABAC压缩：无损压缩

高频短码，低频长码，加上上下文。

## H264数据结构

视频由视频帧组成，图像达到一秒16帧以上就认为是视频。

在网络传输时图片很大，一次传输不了一整张图片，所以每一个图片又可以分成很多片。片有片头（网络传输序号）和片数据。

每一片有很多一个宏块。宏块包括：宏块类型、宏块预测、残差数据。

宏块又可以分成子块。

宏块是H264编码的基本单位。每个宏块选择合适的模式。

编码完成后会得到一个一个的流单元NALU（SPS、PPS、I Frame、P Frame、B Frame）。

## NALU

- 第1位为禁位
- 第2到3位为参考级别
- 第4到8位为nal单元类型

nalu从十六进制转为二进制，第1位不需要，2到3位也不需要，4到8位为流类型。

## VideoToolBox基本概念

VideoToolBox基于coreMedia，coreVideo，coreFundation框架C语言API。

三种类型会话：编码，解码，像素移动。

从coreMedia，coreVideo框架衍生出时间或帧管理数据类型，CMTime，CVPixelBufferRef。

CMVideoFormatDescriptionRef：视频格式描述。包括编码尺寸，视频尺寸。

## CMSampleBufferRef

编码后的视频帧CMSampleBuffer

- CMTime
- CMVideoFormatDescriptionRef
- CMBlockBuffer

未编码的视频帧CMSampleBuffer

- CMTime
- CMVideoFormatDescriptionRef
- CVPixelBuffer

CMBlockBufferRef里面是frame帧

CVPixelBufferRef里面存储的不是RGB而是YUV信息

OpenGLES默认的颜色体系是RGB，需要YUV转换RGB。所以需要两个纹理。

图片数据只有Y数据，可以显示，但是是黑白的，加上UV信息图片才会变成彩色的。

视频由2个图层构成：Y图层和UV图层。

视频渲染就是纹理的渲染，也就是片元着色器填充。width * height正方形（渲染2个纹理）。

### 编码的输入和输出

原始数据（CVPixelBuffers） --> 经过VTCompressionSessionRef（VideoEncoder视频编码器） --> 得到H264文件（CMSampleBufferRefs）

## 视频解码

### 解码思路

1. 解析数据（NALU Unit 流单元）I帧P帧B帧

   既然流数据NALU，一个接一个，所以需要实时解码。

   首先需要对数据解析，分析NALU数据，前面4个字节时起始位，标识一个NALU的开始，所以从第5位才开始来获取，从第五位才是NALU数据类型。

   获取到第5位数据，转化为十进制，然后根据表格判断它的数据类型。

   判断好数据类型，才能将NALU送入解码器。SPS/PPS只要获取就可以了，是不需要解码的。

   `CVPixelBufferRef`保存的是解码后的数据或者未编码前的数据。

2. 初始化解码器

3. 将解析后的H264流数据（NALU Unit）输入到解码器

4. 解码完成后的回调，输出解码数据

5. 解码数据显示，用到OpenGL ES

### 解码三个核心函数

1. 创建session，`VTDecompressionSessionCreate`
2. 解码一个frame，`VTDecompressionSessionDecodeFrame`
3. 销毁解码session，`VTDecompressionSessionInvalidate`

### 原理分析

解码解的是H264原始码流，H264原始码流由一个一个流数据（NALU）组成。

- I帧：保留了一张完整视频帧，解码关键
- P帧：向前参考帧，差异数据，解码需要依赖I帧
- B帧：双向参考帧，解码时即需要I帧，也需要P帧

**如果H264码流中I帧错误或者丢失，就会导致错误传递，P帧B帧单独是完成不了解码工作，解码错误会产生花屏现象。**

**VideoToolBox硬编码H264帧（I帧），手动添加了SPS和PPS。所以解码时需要使用SPS/PPS数据来对解码器进行初始化。**

